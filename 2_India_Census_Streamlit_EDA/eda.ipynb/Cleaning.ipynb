{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67e4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "# clean in excel\n",
    "# pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730795c2",
   "metadata": {},
   "source": [
    "Dataset source - [A-02: Decadal variation in population 1901-2011](https://censusindia.gov.in/census.website/data/census-tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b554f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT OPEN ANY .xlsx FILE WHILE CLEANING\n",
    "\n",
    "# WHAT WE HAVE TO CLEAN\n",
    "# 1) REMOVE UN-NECESSARY COLUMN `Variation since the preceding census`: [Absolute,Percentage]\n",
    "# 2) REMOVE ALL EMPTY ROW AND ROWS UNTIL REACH REQUIRE FIRST DATA\n",
    "# 3) REMOVE COMMENT LINES\n",
    "# ) Ensure proper data types for each column (e.g., numerical data for population figures).\n",
    "# 3) CLEAN `State/Union Territory/District`, REMOVE SPECIAL CHARACTER FROM NAME\n",
    "# 4) CLEAN `Census Year,Persons,Males,Females` REMOVE SPECIAL CHARACTER FROM NUMBER AND REPLACE '-','N.A','N/A','' TO np.nan\n",
    "# 6) REPLACE WRONG 'Census Year' WITH ACTUAL YEAR\n",
    "# 6) DATA FILLING IN 'State,District AND NAME' COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3709f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decade_start(year):\n",
    "    \"\"\"\n",
    "    Determine the start of the decade for a given year based on Indian census rules.\n",
    "    If the last digit of the year is greater than 5, move to the next decade.\n",
    "    \"\"\"\n",
    "    # Is year null\n",
    "    if pd.isnull(year):\n",
    "        return yaar\n",
    "    \n",
    "    # Clean year string\n",
    "    if type(year) != type(int()) and type(year) != type(float()):\n",
    "        if type(year) != type(str()):\n",
    "            print(type(year))\n",
    "            return year # np.nan\n",
    "        \n",
    "        num_or_str = ''.join([x for x in year if x in '0123456789'])\n",
    "        if num_or_str.isdigit():\n",
    "            year = int(num_or_str)\n",
    "        else:\n",
    "            return year\n",
    "    \n",
    "    # Convert the year to an integer\n",
    "    year = int(year)\n",
    "    \n",
    "    # Get the last digit of the year\n",
    "    last_digit = year % 10\n",
    "    \n",
    "    # Determine the start of the current decade\n",
    "    current_decade_start = year - (year % 10)\n",
    "    \n",
    "    # Determine if we need to move to the next decade\n",
    "    if last_digit > 5:\n",
    "        # Move to the start of the next decade\n",
    "        next_decade_start = current_decade_start + 10\n",
    "        return next_decade_start + 1\n",
    "    else:\n",
    "        # Stay in the current decade\n",
    "        return current_decade_start + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ca036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_optimise_population_dataset(df=None):\n",
    "    # COLUMNS\n",
    "    \n",
    "    # select same column for all\n",
    "    while type(df.columns[0]) != type(str()) or 'state' not in df.columns[0].lower():\n",
    "        df.columns = df.head(1).values[0]\n",
    "        df.drop([df.head(1).index.values[0]], inplace=True)\n",
    "        # is row left?\n",
    "        if len(df.head(1).index) == 0: return pd.DataFrame({})\n",
    "        \n",
    "    print(df.columns)\n",
    "    \n",
    "    # drop column\n",
    "    df = df.drop(columns=[col for col in df.columns if type(col) != type(str()) or 'since' in col.lower() or 'unnamed' in col.lower()])\n",
    "    if df.shape[1] == 0: return pd.DataFrame({}) # sometime all cols deleted\n",
    "    # rename column\n",
    "    df.columns = ['State Code','District Code','District Name','Census Year','Persons','Males', 'Females']\n",
    "            \n",
    "\n",
    "    # REMOVE ROW\n",
    "    # remove fully empty row\n",
    "    df = df.dropna(how='all')\n",
    "    # Create a condition to identify rows where 'Persons' are NaN\n",
    "    condition = df['Persons'].isnull() | (df['Males'].isnull() & df['Females'].isnull())\n",
    "    df = df[~condition] # remove comment row\n",
    "    # remove headers row until first 'District Name' is not null, not number and is string\n",
    "    head = df.head(1)\n",
    "    state_code = head['State Code'].values[0]\n",
    "    district_code = head['District Code'].values[0]\n",
    "    district_name = head['District Name'].values[0]\n",
    "    \n",
    "    while (pd.isnull(state_code) or pd.isnull(district_code) or pd.isnull(district_name)) or (str(district_name).isdigit() or type(district_name) != type(str())):\n",
    "        df.drop([head.index.values[0]], inplace=True)\n",
    "        head = df.head(1)\n",
    "        \n",
    "        state_code = head['State Code'].values[0]\n",
    "        district_code = head['District Code'].values[0]\n",
    "        district_name = head['District Name'].values[0]\n",
    "    \n",
    "        # sometime all rows deleted\n",
    "        if len(head.index) == 0: return pd.DataFrame({})\n",
    "    \n",
    "    \n",
    "    # CLEANING COLUMN\n",
    "    # 'District Name' column (remove special character)\n",
    "    def clean_string(s):\n",
    "        if pd.isna(s) or type(s) == type(int()):  # Check for NaN values and return an empty string\n",
    "            return s\n",
    "        # Remove leading and trailing spaces and special characters (including '&')\n",
    "        s = s.strip()\n",
    "        s = re.sub(r'^[^A-Za-z0-9]+|[^A-Za-z0-9]+$', '', s)\n",
    "        # Remove all unwanted special characters except '&'\n",
    "        s = re.sub(r'[^A-Za-z0-9& ]+', '', s)\n",
    "        # Replace multiple spaces with a single space\n",
    "        s = re.sub(r'\\s+', ' ', s)\n",
    "        # Ensure '&' is not at the start or end\n",
    "        s = s.strip(' &')\n",
    "        # Final strip to ensure no leading or trailing spaces\n",
    "        return np.nan if s.strip() == '' else s.strip()\n",
    "    df['District Name'] = df['District Name'].apply(clean_string)\n",
    "\n",
    "    # 'numeriic'  column (remove special character)\n",
    "    symbols_to_remove = \"\"\"!@#$%^&*()_+-={[]}:;<>?/\\\\.,\\\"' NA\"\"\" # dont use '.' because float contain '.'\n",
    "    #pattern = '|'.join([re.escape(symbol) for symbol in symbols_to_remove])\n",
    "    \n",
    "    def fun_remove_symbol(string):\n",
    "        if type(string) == type(str()) and any([x in str(string) for x in symbols_to_remove]):\n",
    "            new_cell = ''.join([char for char in string if char not in symbols_to_remove])\n",
    "            if new_cell.strip() != '':\n",
    "                return new_cell\n",
    "            else:\n",
    "                return np.nan\n",
    "        else:\n",
    "            return string\n",
    "    \n",
    "    df['Census Year'] = df['Census Year'].apply(fun_remove_symbol)\n",
    "    df['Persons'] = df['Persons'].apply(fun_remove_symbol)\n",
    "    df['Males'] = df['Males'].apply(fun_remove_symbol)\n",
    "    df['Females'] = df['Females'].apply(fun_remove_symbol)\n",
    "    \n",
    "    \n",
    "    # FILLING CELL\n",
    "    df['State Code'] = df['State Code'].fillna(method='ffill')\n",
    "    df['District Code'] = df['District Code'].fillna(method='ffill')\n",
    "    df['District Name'] = df['District Name'].fillna(method='ffill')\n",
    "    \n",
    "    # CORRECT VALUES\n",
    "    df['Census Year'] = df['Census Year'].apply(lambda year: get_decade_start(year))\n",
    "    \n",
    "    \n",
    "    # OPTIMIZE DATATYPE\n",
    "    df['State Code'] = pd.to_numeric(df['State Code'], errors='ignore')\n",
    "    df['District Code'] = pd.to_numeric(df['District Code'], errors='ignore')\n",
    "    df['Census Year'] = pd.to_numeric(df['Census Year'], errors='ignore')\n",
    "    df['Persons'] = pd.to_numeric(df['Persons'], errors='ignore')\n",
    "    df['Males'] = pd.to_numeric(df['Males'], errors='ignore')\n",
    "    df['Females'] = pd.to_numeric(df['Females'], errors='ignore')\n",
    "\n",
    "    \n",
    "    # REMOVE STATE ROW FROM STATE DATAFRAME AFTER CLEANING AND FILLING\n",
    "    if not df.empty:\n",
    "        first_sc = int(df.head(1)['State Code'].values[0])\n",
    "        first_dc = int(df.head(1)['District Code'].values[0])\n",
    "\n",
    "        condition = (df['State Code'] == first_sc) & (df['District Code'] == first_dc)\n",
    "        df = df[~condition]\n",
    "        \n",
    "    \n",
    "    # reset index\n",
    "    df = df.reset_index()\n",
    "    df.drop(columns=['index'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f220e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list of excel file in sys\n",
    "states_xlsx = os.listdir('1. ORGIGNAL/A-02 Decadal variation in population 1901-2011')\n",
    "state_df = {}\n",
    "\n",
    "for state_file in states_xlsx:\n",
    "    print(state_file)\n",
    "    temp_df = pd.read_excel('1. ORGIGNAL/A-02 Decadal variation in population 1901-2011/' + state_file, header=1)\n",
    "    state_df[state_file.split('.xl')[0]] = clean_optimise_population_dataset(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455842c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = state_df[list(state_df.keys())[0]]\n",
    "\n",
    "for d in state_df.keys():\n",
    "    print(d, state_df.get(d).info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa04c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLAMS STILL AFTER CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b09f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) SOME DATAFRAME IS EMPTY 'NEED TO CLEANING SPECIALLY'\n",
    "for key in state_df:\n",
    "    dataframe = state_df[key]\n",
    "    if dataframe.empty: print(key, 'EMPTY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c62139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) MISSING VALUES\n",
    "count = 0\n",
    "for key in state_df:\n",
    "    df = state_df[key]\n",
    "    print(df.isnull().sum())\n",
    "#     count += len(df[df[['Persons','Males','Females']].isnull().any(axis=1)])\n",
    "print(count, 'missing data row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7acf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d8ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Handling NaN values in Persons, Males and Females column\n",
    "\n",
    "for key in state_df:\n",
    "    print(key)\n",
    "    cur_df = state_df[key].copy()\n",
    "\n",
    "    # Sort data by 'District Name' and 'Census Year'\n",
    "    cur_df = cur_df.sort_values(by=['State Code', 'District Code', 'District Name', 'Census Year'])\n",
    "\n",
    "    # Calculate growth rate for each interval\n",
    "    cur_df['Growth Rate'] = cur_df.groupby('District Code')['Persons'].pct_change()\n",
    "\n",
    "    # Calculate mean growth rate for each 'District Name'\n",
    "    mean_growth_rate = cur_df.groupby('District Code')['Growth Rate'].mean().reset_index()\n",
    "    mean_growth_rate.columns = ['District Code', 'Mean Growth Rate']\n",
    "\n",
    "\n",
    "    # This function impute_persons_nearest is designed to impute missing values in the Persons column of a DataFrame \n",
    "    # based on the nearest non-null value, adjusted for a growth rate by year in the same district. \n",
    "    # This approach uses a combination of historical data and a calculated growth rate to estimate missing values\n",
    "\n",
    "    # Define function to impute 'Persons' based on the nearest non-null value\n",
    "    def impute_persons_nearest(row, df, mean_growth_rate):\n",
    "        district_code = row['District Code']\n",
    "        year = row['Census Year']\n",
    "        growth_rate = mean_growth_rate[mean_growth_rate['District Code'] == district_code]['Mean Growth Rate'].values[0]\n",
    "\n",
    "        # Get the index of the current row\n",
    "        current_index = df.index[df['District Code'] == district_code].get_loc(row.name)\n",
    "\n",
    "        # Get indices of non-null 'Persons' values for the same 'District Name'\n",
    "        non_null_indices = df[df['District Code'] == district_code]['Persons'].dropna().index\n",
    "\n",
    "        # Find the nearest non-null value's index\n",
    "        nearest_index = min(non_null_indices, key=lambda x: abs(x - current_index))\n",
    "\n",
    "        # Get the nearest non-null value and its year\n",
    "        nearest_row = df.loc[nearest_index]\n",
    "        nearest_year = nearest_row['Census Year']\n",
    "        nearest_persons = nearest_row['Persons']\n",
    "\n",
    "        # Calculate the number of years between the current year and the nearest year\n",
    "        years_diff = abs(year - nearest_year)/10\n",
    "\n",
    "        # Estimate the missing 'Persons' value based on growth rate\n",
    "        if nearest_year < year:  # If nearest year is before current year\n",
    "            estimated_persons = nearest_persons * ((1 + growth_rate) ** years_diff)\n",
    "        else:  # If nearest year is after current year\n",
    "            estimated_persons = nearest_persons / ((1 + growth_rate) ** years_diff)\n",
    "\n",
    "        return int(estimated_persons)\n",
    "\n",
    "    # Apply the imputation function to rows with missing 'Persons'\n",
    "    cur_df['Persons'] = cur_df.apply(\n",
    "        lambda row: row['Persons'] if pd.notna(row['Persons']) else impute_persons_nearest(row, cur_df, mean_growth_rate),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Handling NaN values in Males and Females column\n",
    "    # For Males: median proportion of males to total persons in the same district\n",
    "    # For Females: Persons - Males\n",
    "\n",
    "    # Define function to impute 'Males' based on the nearest non-null value\n",
    "    def impute_males_nearest(row, df):\n",
    "        district_code = row['District Code']\n",
    "        year = row['Census Year']\n",
    "\n",
    "        notna_distict_df = df[df['District Code'] == district_code].dropna().copy()\n",
    "        notna_distict_df['Male_Per'] = notna_distict_df['Males']/notna_distict_df['Persons']\n",
    "        Male_Percentage_Median = notna_distict_df['Male_Per'].median()\n",
    "\n",
    "        return int(row['Persons']*Male_Percentage_Median)\n",
    "\n",
    "    # Male\n",
    "    cur_df['Males'] = cur_df.apply(\n",
    "        lambda row: row['Males'] if pd.notna(row['Males']) else impute_males_nearest(row, cur_df),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "    # Female\n",
    "    cur_df['Females'] = cur_df.apply(\n",
    "        lambda row: row['Females'] if pd.notna(row['Females']) else row['Persons'] - row['Males'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    cur_df.drop('Growth Rate', axis=1, inplace=True)\n",
    "    state_df[key] = cur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc2457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISSING VALUES\n",
    "count = 0\n",
    "for key in state_df:\n",
    "    df = state_df[key]\n",
    "#     print(df.isnull().sum())\n",
    "    count += len(df[df[['Persons','Males','Females']].isnull().any(axis=1)])\n",
    "print(count, 'missing data row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only remove those rows whose 70% values were nan [initials row, all nan value row, state data, comment line row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ef650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76483d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# COMBINE\n",
    "giant_df = pd.concat([state_df[key] for key in list(state_df.keys())[1:]], axis=0, ignore_index=True)\n",
    "\n",
    "# Add State Name\n",
    "india_state = state_df[list(state_df.keys())[0]][['State Code', 'District Name']].drop_duplicates().copy()\n",
    "india_state.rename(columns={'District Name':'State Name'}, inplace=True)\n",
    "\n",
    "giant_df = india_state.merge(giant_df, how='left', on='State Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf375cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24c83cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change_datatype\n",
    "giant_df['State Code'] = giant_df['State Code'].astype('int8')\n",
    "giant_df['District Code'] = giant_df['District Code'].astype('int16')\n",
    "giant_df['Census Year'] = giant_df['Census Year'].astype('int16')\n",
    "giant_df['Persons'] = giant_df['Persons'].astype('int32')\n",
    "giant_df['Males'] = giant_df['Males'].astype('int32')\n",
    "giant_df['Females'] = giant_df['Females'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf73d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005181d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c7f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d8bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(giant_df, index=['State Code', 'State Name', 'District Code'], columns=['Census Year'], values=['Males', 'Females']) # , aggfunc = np.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "giant_df.to_csv('District Population Census.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be67bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS\n",
    "# SOME DISTICT NAME ARE CHANGE OVER TIME"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
